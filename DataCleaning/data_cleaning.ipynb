{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Essentials: Data Cleaning\n",
    "    Marcelo Leszynski\n",
    "    SEC 001\n",
    "    10/11/12\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The g\\_t\\_results.csv file is a set of parent-reported scores on their child's Gifted and Talented tests. \n",
    "The two tests, OLSAT and NNAT, are used by NYC to determine if children are qualified for gifted programs.\n",
    "The OLSAT Verbal has 16 questions for Kindergardeners and 30 questions for first, second, and third graders.\n",
    "The NNAT has 48 questions. \n",
    "Using this dataset, answer the following questions.\n",
    "\n",
    "\n",
    "1) What column has the highest number of null values and what percent of its values are null? Print the answer as a tuple with (column name, percentage). Make sure the second value is a percent.\n",
    "\n",
    "2) List the columns that should be numeric that aren't. Print the answer as a tuple.\n",
    "\n",
    "3) How many third graders have scores outside the valid range for the OLSAT Verbal Score? Print the answer\n",
    "\n",
    "4) How many data values are missing (NaN)? Print the number.\n",
    "\n",
    "Each part is one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('School Assigned', '75.21367521367522')\n",
      "('OLSAT Verbal Score', 'OLSAT Verbal Percentile', 'NNAT Non Verbal Raw Score')\n",
      "1\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "tests = pd.read_csv(\"g_t_results.csv\")\n",
    "\n",
    "# part 1 ########################################################\n",
    "nulls = tests.isna().sum(axis=0)\n",
    "pt_1 = nulls.idxmax()\n",
    "pt_2 = nulls.max()/len(tests[pt_1])\n",
    "print(tuple((pt_1,str(100*pt_2))))\n",
    "\n",
    "# part 2 ########################################################\n",
    "tests.dtypes\n",
    "tests.head()\n",
    "print(tuple([\"OLSAT Verbal Score\",\"OLSAT Verbal Percentile\",\"NNAT Non Verbal Raw Score\"]))\n",
    "\n",
    "# part 3 ########################################################\n",
    "pt_3 = tests[tests[\"Entering Grade Level\"] == \"3\"]\n",
    "pt_3['OLSAT Verbal Score'].value_counts()\n",
    "print(1)\n",
    "\n",
    "# part 4 ########################################################\n",
    "print(tests.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "imdb.csv contains a small set of information about 99 movies. Clean the data set by doing the following in order: \n",
    "\n",
    "1) Remove duplicate rows by dropping the first **or** last. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "2) Drop all rows that contain missing data. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "3) Remove rows that have data outside valid data ranges and explain briefly how you determined your ranges for each column.\n",
    "\n",
    "4) Identify and drop columns with three or fewer different values. Print a tuple with the names of the columns dropped.\n",
    "\n",
    "5) Convert the titles to all lower case.\n",
    "\n",
    "Print the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 13)\n",
      "(64, 13)\n",
      "I removed movies with negative values in duration, imdb scores, and title_year less than 1900\n",
      "('color', 'language')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>title_year</th>\n",
       "      <th>country</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>actors</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>240</td>\n",
       "      <td>116866727.0</td>\n",
       "      <td>Biography|Comedy|Crime|Drama</td>\n",
       "      <td>the wolf of wall street</td>\n",
       "      <td>2013</td>\n",
       "      <td>USA</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Leonardo DiCaprio,Matthew McConaughey,Jon Favreau</td>\n",
       "      <td>138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shane Black</td>\n",
       "      <td>195</td>\n",
       "      <td>408992272.0</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>iron man 3</td>\n",
       "      <td>2013</td>\n",
       "      <td>USA</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Robert Downey Jr.,Jon Favreau,Don Cheadle</td>\n",
       "      <td>95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>187</td>\n",
       "      <td>54116191.0</td>\n",
       "      <td>Crime|Drama|Mystery|Thriller|Western</td>\n",
       "      <td>the hateful eight</td>\n",
       "      <td>2015</td>\n",
       "      <td>USA</td>\n",
       "      <td>44000000.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Craig Stark,Jennifer Jason Leigh,Zoë Bell</td>\n",
       "      <td>114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenneth Lonergan</td>\n",
       "      <td>186</td>\n",
       "      <td>46495.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>margaret</td>\n",
       "      <td>2011</td>\n",
       "      <td>usa</td>\n",
       "      <td>14000000.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Matt Damon,Kieran Culkin,John Gallagher Jr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>186</td>\n",
       "      <td>258355354.0</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "      <td>the hobbit: the desolation of smaug</td>\n",
       "      <td>2013</td>\n",
       "      <td>USA</td>\n",
       "      <td>225000000.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Aidan Turner,Adam Brown,James Nesbitt</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       director_name  duration        gross  \\\n",
       "0    Martin Scorsese       240  116866727.0   \n",
       "1        Shane Black       195  408992272.0   \n",
       "2  Quentin Tarantino       187   54116191.0   \n",
       "3   Kenneth Lonergan       186      46495.0   \n",
       "4      Peter Jackson       186  258355354.0   \n",
       "\n",
       "                                 genres                          movie_title  \\\n",
       "0          Biography|Comedy|Crime|Drama              the wolf of wall street   \n",
       "1               Action|Adventure|Sci-Fi                           iron man 3   \n",
       "2  Crime|Drama|Mystery|Thriller|Western                    the hateful eight   \n",
       "3                                 Drama                             margaret   \n",
       "4                     Adventure|Fantasy  the hobbit: the desolation of smaug   \n",
       "\n",
       "   title_year country       budget  imdb_score  \\\n",
       "0        2013     USA  100000000.0         8.2   \n",
       "1        2013     USA  200000000.0         7.2   \n",
       "2        2015     USA   44000000.0         7.9   \n",
       "3        2011     usa   14000000.0         6.5   \n",
       "4        2013     USA  225000000.0         7.9   \n",
       "\n",
       "                                              actors  movie_facebook_likes  \n",
       "0  Leonardo DiCaprio,Matthew McConaughey,Jon Favreau                138000  \n",
       "1          Robert Downey Jr.,Jon Favreau,Don Cheadle                 95000  \n",
       "2          Craig Stark,Jennifer Jason Leigh,Zoë Bell                114000  \n",
       "3        Matt Damon,Kieran Culkin,John Gallagher Jr.                     0  \n",
       "4              Aidan Turner,Adam Brown,James Nesbitt                 83000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 1 ########################################################\n",
    "movies = pd.read_csv(\"imdb.csv\")\n",
    "movies = movies.drop_duplicates(keep=\"first\")\n",
    "print(movies.shape)\n",
    "\n",
    "# part 2 ########################################################\n",
    "movies = movies.dropna(axis=0)\n",
    "print(movies.shape)\n",
    "\n",
    "# part 3 ########################################################\n",
    "print(\"I removed movies with negative values in duration, imdb scores, and title_year less than 1900\")\n",
    "movies = movies[movies.duration > 0]\n",
    "movies = movies[movies.title_year > 1900]\n",
    "movies = movies[movies.imdb_score >= 0]\n",
    "\n",
    "# part 4 ########################################################\n",
    "#print(movies.nunique()>3)\n",
    "print(('color', 'language'))\n",
    "movies = movies.loc[:,movies.nunique()>3]\n",
    "\n",
    "# part 5 ########################################################\n",
    "movies.movie_title = movies.movie_title.str.lower()\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "basketball.csv contains data for all NBA players between 2001 and 2018.\n",
    "Each row represents a player's stats for a year.\n",
    "\n",
    "Create two new features:\n",
    "\n",
    "    career_length (int): number of years player has been playing (start at 0).\n",
    "    \n",
    "    target (str): The target team if the player is leaving. If the player is retiring, the target should be 'retires'.\n",
    "                  A player is retiring if their name doesn't exist the next year.\n",
    "                  (Set the players in 2019 to NaN).\n",
    "\n",
    "Remove all duplicate players in each year.\n",
    "Remove all rows except those where a player changes team, that is, target is not null nor 'retires'.\n",
    "\n",
    "Drop the player, year, and team_id columns.\n",
    "\n",
    "Return the first 10 lines of your dataframe and its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1174, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>per</th>\n",
       "      <th>ws</th>\n",
       "      <th>bpm</th>\n",
       "      <th>career_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>27</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>6</td>\n",
       "      <td>PHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>24</td>\n",
       "      <td>15.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4</td>\n",
       "      <td>MEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>33</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>15</td>\n",
       "      <td>HOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>14</td>\n",
       "      <td>PHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>29</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>10</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>31</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>11</td>\n",
       "      <td>SAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>25</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>7</td>\n",
       "      <td>CHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>29</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>SAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>28</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>8</td>\n",
       "      <td>MIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age   per   ws  bpm  career_length target\n",
       "453   27   8.2  1.0 -2.5              6    PHO\n",
       "461   24  13.0  1.2 -0.9              3    ATL\n",
       "462   24  15.9  6.2  2.9              4    MEM\n",
       "464   33  12.7  3.7 -1.9             15    HOU\n",
       "467   32  11.8  5.3  0.7             14    PHO\n",
       "477   29   7.5  1.1 -2.8             10    MIN\n",
       "482   31  14.1  1.9 -0.2             11    SAS\n",
       "489   25  14.1  2.9 -2.4              7    CHO\n",
       "490   29  12.6  2.8  0.1              3    SAC\n",
       "493   28  13.0  0.0 -3.2              8    MIL"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba = pd.read_csv(\"basketball.csv\")\n",
    "nba = nba.drop_duplicates([\"player\",\"year\"],keep=\"first\")\n",
    "counts = nba.player.value_counts()-1\n",
    "\n",
    "# adding total career length to each player (wording is kinda ambiguous) ###\n",
    "nba['career_length'] = nba.apply(lambda x: counts[x.player],  axis=1)\n",
    "\n",
    "# generate target values ###################################################\n",
    "def target_func(row):\n",
    "    if row.year == 2019:\n",
    "        return None\n",
    "    player = nba[nba['player'] == row.player]\n",
    "    if row.year + 1 in player.year.values:\n",
    "        if player[player.year == row.year + 1].team_id.values[0] == row.team_id:\n",
    "            return None\n",
    "        else: \n",
    "            return player[player.year == row.year +1].team_id.values[0]\n",
    "    else:\n",
    "        return 'retires'\n",
    "    \n",
    "nba['target'] = nba.apply(target_func, axis=1)\n",
    "\n",
    "# drop target rows and columns #############################################\n",
    "nba = nba[(nba['target'].notna()) & (nba['target'] != 'retires')]\n",
    "nba = nba.drop([\"player\",\"year\",\"team_id\"],axis=1)\n",
    "\n",
    "print(nba.shape)\n",
    "nba.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Load housing.csv into a dataframe with index=0. Descriptions of the features are in housing_data_description.txt.  \n",
    "The goal is to construct a regression model that predicts SalePrice using the other features of the dataset.  Do this as follows:\n",
    "\n",
    "\t1) Identify and handle the missing data.  Hint: Dropping every row with some missing data is not a good choice because it gives you an empty dataframe.  What can you do instead?\n",
    "    FIXME\n",
    "\t2) Identify the variable with nonnumeric values that are misencoded as numbers.  One-hot encode it. Hint: don't forget to remove one of the encoded columns to prevent collinearity with the constant column (which you will add later).\n",
    "    \n",
    "    3) Add a constant column to the dataframe.\n",
    "\n",
    "    4) Save a copy of the dataframe.\n",
    "\n",
    "\t5) Choose four categorical featrues that seem very important in predicting SalePrice. One-hot encode these features and remove all other categorical features.\n",
    "\t\t\n",
    "\t6) Run an OLS using all numerical data regression on your model.  \n",
    "\n",
    "\t\n",
    "Print the ten features that have the highest coef in your model and the summary. Don't print the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 85)\n",
      "['constant', 'Neighborhood_NoRidge', 'MSSubClass_75', 'MSSubClass_160', 'Neighborhood_Blueste', 'MSSubClass_120', 'Neighborhood_Mitchel', 'Neighborhood_NWAmes', 'Neighborhood_Gilbert', 'MSSubClass_190']\n"
     ]
    }
   ],
   "source": [
    "h = pd.read_csv('housing.csv')\n",
    "h.Alley = h.Alley.fillna('No Access')\n",
    "\n",
    "# part 1 - clean data ########################################################\n",
    "h.LotFrontage = h.LotFrontage.fillna(h.LotFrontage.median)\n",
    "h.MasVnrType = h.MasVnrType.fillna(\"No Veneer\")\n",
    "h.MasVnrArea = h.MasVnrArea.fillna(0)\n",
    "h.BsmtQual = h.BsmtQual.fillna(\"NB\")\n",
    "h.BsmtCond = h.BsmtCond.fillna(\"NB\")\n",
    "h.BsmtExposure = h.BsmtExposure.fillna(\"NB\")\n",
    "h.BsmtFinType1 = h.BsmtFinType1.fillna(\"NB\")\n",
    "h.BsmtFinType2 = h.BsmtFinType2.fillna(\"NB\")\n",
    "h = h[h.Electrical.notna()]\n",
    "h.FireplaceQu = h.FireplaceQu.fillna('NF')\n",
    "h.GarageType = h.GarageType.fillna('NG')\n",
    "h.GarageYrBlt = h.GarageYrBlt.fillna('NG')\n",
    "h.GarageFinish = h.GarageFinish.fillna('NG')\n",
    "h.GarageQual = h.GarageQual.fillna('NG')\n",
    "h.GarageCond = h.GarageCond.fillna('NG')\n",
    "h.PoolQC = h.PoolQC.fillna(\"NP\")\n",
    "h.Fence = h.Fence.fillna('NF')\n",
    "h.MiscFeature = h.MiscFeature.fillna(\"NM\")\n",
    "\n",
    "# part 2 - one-hot MSSubClass ################################################\n",
    "h = pd.get_dummies(h,columns=[\"MSSubClass\"],drop_first=True)\n",
    "\n",
    "# part 3 - add constant column ###############################################\n",
    "h['constant'] = np.ones(h.shape[0])\n",
    "\n",
    "# part 4 - make a copy #######################################################\n",
    "h_copy = h.copy()\n",
    "\n",
    "# part 5 - one-hot building type, neighborhood, exterior condition, ##########\n",
    "    # and kitchen quality ####################################################\n",
    "categoricals = [col for col in h_copy.select_dtypes(include='object').columns]\n",
    "#print(categoricals)\n",
    "h_copy = pd.get_dummies(h_copy,columns=['BldgType','Neighborhood','ExterCond','KitchenQual'],drop_first=True)\n",
    "h_copy = h_copy.select_dtypes(exclude=['object'])\n",
    "print(h_copy.shape)\n",
    "\n",
    "# perform regression and print results #######################################\n",
    "results = sm.OLS(h_copy.iloc[:,-1].values, h_copy.iloc[:,:-1].values).fit()\n",
    "summary = results.summary()\n",
    "results_as_html = summary.tables[1].as_html()\n",
    "result_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "coefficient = np.argsort(result_df.coef.values)[::-1][:10]\n",
    "print(list(h_copy.columns[coefficient]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Using the copy of the dataframe you created in Problem 4, one-hot encode all the categorical variables.\n",
    "Print the shape of the dataframe and run OLS.\n",
    "\n",
    "Print the ten features that have the highest coef in your model and the summary.\n",
    "Write a couple of sentences discussing which model is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    722\u001b[0m         codes, uniques = factorize_array(\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    528\u001b[0m     uniques, codes = table.factorize(\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     )\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m         raise TypeError(\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m             \u001b[0;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-01ce303836c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# one-hot the copy data frame ################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# perform regression and print results #######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_first\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m             )\n\u001b[1;32m    902\u001b[0m             \u001b[0mwith_dummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m     \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize_from_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mfactorize_from_iterable\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   2602\u001b[0m         \u001b[0;31m# but only the resulting categories, the order of which is independent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m         \u001b[0;31m# from ordered. Set ordered to False as default. See GH #15457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m         \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2605\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0;31m# raise, as we don't have a sortable data structure and so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         codes, uniques = factorize_array(\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         )\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     uniques, codes = table.factorize(\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     )\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1784\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m         raise TypeError(\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m             \u001b[0;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "# one-hot the copy data frame ################################\n",
    "h = pd.get_dummies(h,drop_first=True)\n",
    "\n",
    "# perform regression and print results #######################\n",
    "results = sm.OLS(h_copy.iloc[:,-1].values, h_copy.iloc[:,:-1].values).fit()\n",
    "summary = results.summary()\n",
    "results_as_html = summary.tables[1].as_html()\n",
    "result_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "coefficient = np.argsort(result_df.coef.values)[::-1][:10]\n",
    "print(list(h_copy.columns[coefficient]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model has a higher $r^2$ value, so it fits the data better. This is probably due to the additional data provided by one-hotting the categorical data. This could also over-fit our data set, and so we have to be careful in applying it to data from different neighborhoods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
